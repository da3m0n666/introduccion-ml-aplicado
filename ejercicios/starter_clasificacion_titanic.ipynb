{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R4pO1-XtF_a0"
   },
   "source": [
    "\n",
    "# Modelos de Clasificación para Predecir Sobrevivientes del Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1oBG5vpAF_a2"
   },
   "source": [
    "![](https://raw.githubusercontent.com/petobens/introduccion-ml-aplicado/class3/figures/ml-claro-2/titanic.jpg)\n",
    "\n",
    "\n",
    "En general los conceptos del universo de problemas de regresión se trasladan al caso de clasificación con pequeñas diferencias.\n",
    "\n",
    "\n",
    "Nuestro *target* es ahora una variable discreta o categórica de forma que el objetivo es clasificar etiquetas desconocidas en distintas clases.\n",
    "\n",
    "Numerosos problemas pueden modelarse de este modo (rotulado de correo basura, churn, probabilidad de default, etc.).\n",
    "\n",
    "\n",
    "Queremos que nuestro clasificador estimado, $\\hat{f}$, minimice ahora la siguiente función:\n",
    "\n",
    "$$\\frac{1}{p}\\sum_{i=1}^{p}I(y_{i} \\not = \\hat{y}_{i})$$\n",
    "     \n",
    "Donde $I(\\cdot)$ es una función que vale 1 si $y_{i} \\not = \\hat{y}_{i}$ y 0 en caso contrario.\n",
    "\n",
    "Básicamente deseamos reducir la proporción de errores que cometemos.\n",
    "\n",
    "Esencialmente estamos intentando buscar una frontera de decisión (en el sentido que minimice el error de arriba)\n",
    "\n",
    "Algunos clasificadores conocidos: Bayes ingenuo, k-vecinos más cercanos, regresión logística, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gZv1paTSF_a3"
   },
   "source": [
    "## Extracción de datos para clasificación\n",
    "\n",
    "### Ejercicios\n",
    "1. Escriba una función que obtenga, a partir de [http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.csv](http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.csv) y utilizando Pandas, el conjunto de datos de pasajeros involucrados en el hundimiento del Titanic y lo guarde en un un archivo `titanic_local.csv`\n",
    "\n",
    "2. Agregue lógica de cache que reuse la copia local del conjunto de datos, en caso que esta exista, y evite de ese modo consultar repetidas veces el enlace de arriba.\n",
    "\n",
    "3. Parta este conjunto de datos de forma aleatoria en dos partes de manera tal que un subconjunto tenga el 70\\% de los registros.\n",
    "\n",
    "4. ¿Cómo puede garantizar que lo hecho en el inciso anterior sea replicable?  Fije la semilla del generador de números aleatorios en `1 2 3 4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iisQpkLeF_a4"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-osPhEa4F_a_"
   },
   "outputs": [],
   "source": [
    "def extract_titanic_data(url, refresh_cache=False):\n",
    "    cache_fn = Path('titanic.csv')\n",
    "    if not cache_fn.exists() or refresh_cache:\n",
    "        print(\"Getting data\")\n",
    "        df = pd.read_csv(url)\n",
    "        df.to_csv(cache_fn, index=False)\n",
    "    else:\n",
    "        print(\"Using cache\")\n",
    "        df = pd.read_csv(cache_fn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kPrCbdIXF_bF"
   },
   "outputs": [],
   "source": [
    "url = 'http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3.csv'\n",
    "df_raw = extract_titanic_data(url)\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGpDyPNhF_bO"
   },
   "outputs": [],
   "source": [
    "# Split data en train y holdout\n",
    "np.random.seed(1234)\n",
    "msk = np.random.rand(len(df_raw)) >= 0.3\n",
    "df_train = df_raw[msk]\n",
    "df_test = df_raw[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NBwvS9r3F_bU"
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RkBy7YvWF_ba"
   },
   "outputs": [],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6WcbU7Z1F_bg"
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MHt6Z4WpF_bn"
   },
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cQ11QicUF_bt"
   },
   "source": [
    "## Primer preproceso / EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZCwhivJLF_bu"
   },
   "source": [
    "\n",
    "![](https://raw.githubusercontent.com/petobens/introduccion-ml-aplicado/class3/figures/ml-claro-2/table_variables.png)\n",
    "\n",
    "### Ejercicios\n",
    "\n",
    "1. Escriba una función que permita convertir (*castear*) múltiples columnas de un tipo de dato a otro y utilícela para asegurar que sus datos sean consistentes con la tabla arriba.\n",
    "\n",
    "2. ¿Qué variables puede usted ignorar? ¿Por qué? Escriba una función que reciba un dataframe y una lista de columnas a eliminar y devuelva un el data frame sin estas columnas. Loguee cuáles columnas fueron eliminadas.\n",
    "\n",
    "3. Una los conjuntos de entrenamiento y validación en único dataframe con una columna de booleanos indicando pertenencia al conjunto de entrenamiento. ¿Por qué tiene sentido trabajar con un set de datos de esta forma?\n",
    "\n",
    "4. ¿Tiene clases desbalanceadas? Haga un gráfico de barras para responder esta pregunta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IGfIRg3zF_bv"
   },
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FjbOn8heF_b0"
   },
   "outputs": [],
   "source": [
    "# Tiene sentido dropear boat (y tambien body)\n",
    "survived_with_boat = len(df_train[(~df_train['boat'].isnull()) & (df_train['survived'] == 1)])\n",
    "survived = len(df_train[df_train['survived'] == 1])\n",
    "(survived_with_boat / survived) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_C6USbA6F_b6"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s-%(name)s-%(levelname)s: %(message)s',\n",
    "    handlers=[logging.FileHandler('titanic.log'), logging.StreamHandler()],\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SbF5qUM2F_b-"
   },
   "outputs": [],
   "source": [
    "def _drop_unusable_cols(df, cols=[]):\n",
    "    logger.info(\n",
    "        f\"Dropping the following {len(cols)} unusable columns:\\n\"\n",
    "        f\"{cols}\"\n",
    "    )\n",
    "    #df.drop(cols, axis=1, inplace=True)\n",
    "    df = df.drop(cols, axis=1)\n",
    "    logger.info(\n",
    "        f\"Remaining {len(df.columns)} columns:\\n {sorted(df.columns.tolist())}\"\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "by2NA5Y4F_cC"
   },
   "outputs": [],
   "source": [
    "df_train = _drop_unusable_cols(df_train, cols=['boat', 'body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sWUdQXQiF_cG"
   },
   "outputs": [],
   "source": [
    "df_train.columns, df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IVCOKG36F_cL"
   },
   "outputs": [],
   "source": [
    "df_test = _drop_unusable_cols(df_test, cols=['boat', 'body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kjVhx9nMF_cP"
   },
   "outputs": [],
   "source": [
    "# Join train test\n",
    "df_train['train'] = True\n",
    "df_test['train'] = False\n",
    "df = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ooAHBeXSF_cS"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szoGU15vF_cX"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_GkC-k3F_cb"
   },
   "outputs": [],
   "source": [
    "pd.value_counts(df['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gyh0pXy6F_cl"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd.value_counts(df['survived'], normalize=True).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q2ompXNsF_cq"
   },
   "source": [
    "## EDA\n",
    "\n",
    "Vamos a utilizar `Seaborn` para hacer algunas visualizaciones estadísticas.\n",
    "\n",
    "![](https://www.fromthegenesis.com/wp-content/uploads/2018/11/seaborn.jpg)\n",
    "\n",
    "\n",
    "Seaborn es una librería de visualización de datos de Python basada en `matplotlib`. \n",
    "\n",
    "Proporciona una interfaz de alto nivel para dibujar gráficos estadísticos atractivos e informativos.\n",
    "\n",
    "Tiene como objetivo hacer que la visualización sea una parte central de la exploración y comprensión de los datos. \n",
    "\n",
    "\n",
    "Veamos primero correlaciones de los atributos numéricos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pPw725-8F_cq"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1NityWquF_cu"
   },
   "outputs": [],
   "source": [
    "g = sns.heatmap(df[['survived', 'age', 'parch', 'fare', 'sibsp']].corr(),\n",
    "                annot=True, fmt = \".2f\", cmap = \"coolwarm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UeHSO2mpYX1X"
   },
   "source": [
    "Solamente el precio del boleto parece estar correlacionado con la probabilidad de supervivencia... ¿debemos descartar las otras variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DqTTOfwTF_cx"
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df, col='survived')\n",
    "g = g.map(sns.distplot, 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DT_R_4WmF_c2"
   },
   "outputs": [],
   "source": [
    "g = sns.kdeplot(df['age'][(df['survived'] == 0) & \n",
    "                             (df['age'].notnull())], color='Red', shade = True)\n",
    "g = sns.kdeplot(df['age'][(df['survived'] == 1) & \n",
    "                             (df['age'].notnull())], color='Blue', shade = True)\n",
    "g.set_xlabel('age')\n",
    "g.set_ylabel('Frequency')\n",
    "g = g.legend(['Not Survived', 'Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wvFmSYVZZhJ9"
   },
   "source": [
    "### Ejercicios: Visualizaciones como herramienta de EDA\n",
    "\n",
    "1. Use la función distplot para graficar la distribución del precio de boletos.\n",
    "  1. ¿Es la distribución resultante asimétrica/sesgada? En caso afirmativo aplique alguna transformación sobre la variable y grafique la nueva distribución.\n",
    "2. ¿Son los hombres o las mujeres más propensos a sobrevivir? Grafique la\n",
    "probabilidad de supervivencia para cada caso y compute el valor exacto de las\n",
    "mismas.\n",
    "3. ¿Hay alguna clase del barco que garantice mayor probabilidad de supervivencia?\n",
    "¿Es este resultado robusto a controlar por sexo? Hint: use la función catplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cI9MgrE7F_c7"
   },
   "outputs": [],
   "source": [
    "df[df['fare'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XOKDHlSDF_c-"
   },
   "outputs": [],
   "source": [
    "df['fare'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gPRkjmrDF_dB"
   },
   "outputs": [],
   "source": [
    "df[df['fare'].fillna(df['fare'].mean()).isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9H51nxS-F_dE"
   },
   "outputs": [],
   "source": [
    "# Distribución de precio de boletos \n",
    "g = sns.distplot(df['fare'].fillna(df['fare'].mean()), color='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o8k90T5iF_dI"
   },
   "outputs": [],
   "source": [
    "df[df['fare'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z4Gjw0e0F_dL"
   },
   "outputs": [],
   "source": [
    "df['fare'] = df['fare'].map(lambda i: np.log(i) if i > 0 else 0)\n",
    "g = sns.distplot(df['fare'].fillna(df['fare'].mean()), color='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e5B5LEI-F_dP"
   },
   "outputs": [],
   "source": [
    "g = sns.barplot(x='sex', y='survived', data=df)\n",
    "g = g.set_ylabel(\"Survival Probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iaV223STF_dS"
   },
   "outputs": [],
   "source": [
    "df[['sex', 'survived']].groupby('sex').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z20sohtsF_dU"
   },
   "outputs": [],
   "source": [
    "g = sns.catplot(x='pclass', y='survived', hue='sex', data=df,\n",
    "                   height=6, kind='bar')\n",
    "g = g.set_ylabels(\"survival probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lL76rJSuF_dZ"
   },
   "source": [
    "## Valores faltantes, repetidos, constantes y extremos\n",
    "\n",
    "1. ¿Cuál es la frecuencia de valores nulos o faltantes? ¿Vale la pena descartar por esto motivo alguna variable? ¿Imputamos valores? ¿Qué valor usar?\n",
    "\n",
    "2. ¿Tienen contenido informativo aquellas variable con nula o cuasi-nula varianza?\n",
    "\n",
    "3. ¿Tiene sentido reemplazar valores extremos?\n",
    "\n",
    "\n",
    "## Ejercicios : Trabajando con valores nulos y constantes\n",
    "1. Escriba una función que i) para cada atributo compute la proporción de valores nulos y ii) en caso que esta supere un determinado umbral elimine dicha columna.\n",
    "  1. Potencialmente podría borrar información importantes (como el target!). ¿Cómo puede modificar la función anterior para proteger a esta columnas?\n",
    "\n",
    "2. En espíritu similar al punto anterior escriba una función que elimine, si las hay, columnas con nula o cuasi nula varianza.\n",
    "\n",
    "3. Escriba una función o lógica que permita rellenar valores de atributos numéricos por su mediana. ¿Cómo puede extender esto a atributos categóricos? Hint: le puede primero servir escribir una función auxiliar que identifique las columnas por tipo (categórica o numérica)\n",
    "\n",
    "4. Sugiera/piense mejoras sobre el procesamiento hecho en los puntos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YsZW5tphF_dZ"
   },
   "outputs": [],
   "source": [
    "df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nvWQgmuBF_dd"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UL5UwXyAF_df"
   },
   "outputs": [],
   "source": [
    "(df.isnull().mean() < 0.5).index.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ySRq8Xx-F_dj"
   },
   "outputs": [],
   "source": [
    "def _drop_nulls(df, max_null_prop=0.5):\n",
    "    logger.info(\n",
    "        f\"Dropping columns with null ratio greater than {max_null_prop * 100}%...\"\n",
    "    )\n",
    "    null_means = df.isnull().mean()\n",
    "    null_mask = null_means < max_null_prop\n",
    "    null_mask[[c for c in null_mask.index.tolist() if c in PROTECTED_COLS]] = True\n",
    "    drop_cols = null_mask[~null_mask].index.tolist()\n",
    "    logger.info(\n",
    "        f\"null proportions:\\n\"\n",
    "        f\"{null_means.loc[drop_cols].sort_values(ascending=False)}\"\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Dropping the following {len(drop_cols)} columns:\\n {drop_cols}\")\n",
    "\n",
    "    df = df.drop(drop_cols, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yL7TzUJYF_dm"
   },
   "outputs": [],
   "source": [
    "PROTECTED_COLS = ['survived', 'train']\n",
    "df = _drop_nulls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aBxwj6iYF_dq"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GYFO8-DOF_du"
   },
   "outputs": [],
   "source": [
    "df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6xgH39HxF_dw"
   },
   "outputs": [],
   "source": [
    "def _drop_std(df, min_std_dev=1.5e-2):\n",
    "    std_values = df.std()\n",
    "    low_variance_cols = std_values < min_std_dev\n",
    "    low_variance_cols = low_variance_cols.index[low_variance_cols].tolist()\n",
    "    low_variance_cols = [c for c in low_variance_cols if c not in PROTECTED_COLS]\n",
    "    logger.info(\n",
    "        f'Dropping the following {len(low_variance_cols)} columns '\n",
    "        f'due to low variance:\\n {low_variance_cols}'\n",
    "    )\n",
    "    df.drop(low_variance_cols, axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CW4pGlWnF_d1"
   },
   "outputs": [],
   "source": [
    "df = _drop_std(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lHZT7XF3F_d7"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IxMym1K0F_d_"
   },
   "outputs": [],
   "source": [
    "df.embarked.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W0W-JB4IF_eB"
   },
   "outputs": [],
   "source": [
    "def _get_typed_cols(df, col_type='cat'):\n",
    "    assert col_type in ('cat', 'num')\n",
    "    include = 'object' if col_type == 'cat' else [np.number]\n",
    "    typed_cols = [\n",
    "        c for c in df.select_dtypes(include=include).columns if c not in PROTECTED_COLS\n",
    "    ]\n",
    "    return typed_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PFdyZ3gLF_eD"
   },
   "outputs": [],
   "source": [
    "num_cols = _get_typed_cols(df, col_type='num')\n",
    "cat_cols = _get_typed_cols(df, col_type='cat')\n",
    "num_cols, cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "29aBnF6aF_eF"
   },
   "outputs": [],
   "source": [
    "df['sex'].value_counts().index.to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SBkHOx-wF_eH"
   },
   "outputs": [],
   "source": [
    "def _fill_nulls(df):\n",
    "    for t in ['num', 'cat']:\n",
    "        cols = _get_typed_cols(df, col_type=t)\n",
    "        for c in cols:\n",
    "            if t == 'num':\n",
    "                df[c] = df[c].fillna(df[c].median())\n",
    "            else:\n",
    "                val_count = df[c].value_counts(dropna=True)\n",
    "                common_val = val_count.index.tolist()[0]\n",
    "                df[c] = df[c].fillna(common_val)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FxWsCoGbF_eJ"
   },
   "outputs": [],
   "source": [
    "df = _fill_nulls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4aEwkw8bF_eM"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JlGPArqOF_eQ"
   },
   "outputs": [],
   "source": [
    "df.embarked.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6S-eima3F_eU"
   },
   "source": [
    "\n",
    "## \"*Applied Machine Learning is basically Feature Engineering*\" - Andrew Ng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M3OsMykJF_eV"
   },
   "source": [
    "\n",
    "## Ingeniería de Atributos (Feature Engineering)\n",
    "### Ejercicios\n",
    "\n",
    "1. Cree un nuevo atributo family_size con el tamaño de la familia de cada pasajero (incluyendo a el mismo).\n",
    "2. Dado este nuevo atributo genere 3 atributos adicionales que remitan a familias de un único miembro, de 2 a 4 miembros y mayor o igual a 5.\n",
    "3. Haga uno (o varios) gráficos comparando la probabilidad de supervivencia de cada una de estas familias.\n",
    "4. Bonus: Extraiga un prefijo a partir de la columna de boletos siempre y cuando el valor de esa columna no sea numerico. Reemplace esta columna por dicho prefijo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HbhdQx3UF_eV"
   },
   "outputs": [],
   "source": [
    "df.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WoW8d2cBF_eY"
   },
   "outputs": [],
   "source": [
    "df.name.str.split(',').str[-1].str.split('.').str[0].str.strip().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jv03rx9-F_ea"
   },
   "outputs": [],
   "source": [
    "# Creamos un nuevo atributo \"titulo\"\n",
    "df['title'] = df.name.str.split(',').str[-1].str.split('.').str[0].str.strip()\n",
    "df['title'] = df['title'].replace(\n",
    "    df.title.value_counts(dropna=False).index.tolist()[4:], 'other'\n",
    ")\n",
    "df['title'] = df['title'].replace(['Miss'], 'Mrs')\n",
    "df = df.drop(['name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BVjhLqFYF_ee"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a4Buv2xLF_ei"
   },
   "outputs": [],
   "source": [
    "df.title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hoh_gJg_F_em"
   },
   "outputs": [],
   "source": [
    "g = sns.countplot(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NFGZydXOF_ep"
   },
   "outputs": [],
   "source": [
    "g = sns.catplot(x='title',y='survived',data=df,kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "knMyzA4jF_er"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XxrmwuFzF_et"
   },
   "outputs": [],
   "source": [
    "df['family_size'] = df['parch'] + df['sibsp'] + 1\n",
    "df['family_single'] = df['family_size'] == 1\n",
    "df['family_small'] = (df['family_size'] > 1) & (df['family_size'] <= 4)\n",
    "df['family_large'] = df['family_size'] > 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_Z38QXeF_ev"
   },
   "outputs": [],
   "source": [
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qBs9__btF_ex"
   },
   "outputs": [],
   "source": [
    "for fsize in ['single', 'small', 'large']:\n",
    "    g = sns.catplot(x=f'family_{fsize}',y='survived',data=df,kind=\"bar\")\n",
    "    g = g.set_ylabels(\"Survival Probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-UZO0A8tF_ez"
   },
   "outputs": [],
   "source": [
    "df.ticket.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wd0vetz4F_e2"
   },
   "outputs": [],
   "source": [
    "# Ticket prefix\n",
    "def extract_ticket_prefix(i):\n",
    "    if not i.isdigit() :\n",
    "        rv = i.replace('.',\"\").replace('/',\"\").strip().split(' ')[0]\n",
    "    else:\n",
    "        rv = 'X'\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LRlyWC6mF_e3"
   },
   "outputs": [],
   "source": [
    "df['ticket'] = df['ticket'].apply(extract_ticket_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "APd_oWlcF_e5"
   },
   "outputs": [],
   "source": [
    "df.ticket.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MI6goqT3F_e7"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PJ-vNRh_F_e_"
   },
   "source": [
    "## Regresión Logística\n",
    "\n",
    "Supongamos que queremos modelar la probabilidad que un cliente cancele o no su línea de celular\n",
    "\n",
    "Podriamos pensar en un modelo de regresión lineal como los ya vistos:\n",
    "          $$Y_{t} = \\beta_{0} + \\beta_{1}X_{t-k} + \\varepsilon_{t}$$\n",
    "\n",
    "En base a esto definir un cliente \"cancelador\" si $\\hat{Y} > 0.5$\n",
    "\n",
    "Pero... el target no caerá necesariamente en el intervalo $[0,1]$.\n",
    "\n",
    "Tiene sentido en cambio formular el problema como\n",
    "        $$\\Pr(Y_{t} = 1) = F(\\beta_{0} + \\beta_{1}X_{t-k} + \\varepsilon_{t})$$\n",
    "\n",
    "Donde $F(\\cdot)$ es la función logística dada por $F(\\cdot) = \\frac{1}{1 + e^{-x}}$\n",
    "    \n",
    "```python\n",
    "  >>> x = np.linspace(-5, 5, 100)\n",
    "  >>> y = 1 / (1 + np.exp(-x))\n",
    "  >>> plt.plot(x, y)\n",
    "```\n",
    "![](https://raw.githubusercontent.com/petobens/introduccion-ml-aplicado/class3/figures/ml-claro-1/logistic.png)\n",
    "\n",
    "\n",
    "### Métricas de Peformance\n",
    "\n",
    "En general estos modelos devuelven estimaciones de probabilidades condicionales.\n",
    "\n",
    "¿Cómo sabemos si fueron buenas?\n",
    "\n",
    "Necesitamos alguna métrica de evaluación. Una matriz de confusión nos permite definir algunas:\n",
    "\n",
    "![](https://raw.githubusercontent.com/petobens/introduccion-ml-aplicado/class3/figures/ml-claro-1/confusion_matrix.png)\n",
    "\n",
    "Hay dos tipos de errores: falsos positivos y falsos negativos\n",
    "\n",
    "* Podemos derivar métricas en base a estos errores\n",
    "\n",
    "*  La más “natural” se conoce como exactitud o accuracy definida por el ratio de clasificaciones correctas sobre el total realizado:\n",
    "\n",
    "$$\\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "\n",
    "¿Es una buena métrica? Puede ser engañosas...\n",
    "\n",
    "\n",
    "![](https://raw.githubusercontent.com/petobens/introduccion-ml-aplicado/class3/figures/ml-claro-1/unbalance_class.png)\n",
    "\n",
    "\n",
    "Imaginemos el caso último panel con una proporción de 1 caso positivo cada 100\n",
    "\n",
    "Un clasificador trivial que prediga siempre la clase negativa tiene una exactitud del 99 %.\n",
    "\n",
    "¿Podemos construir una métrica para evitar esta situación? Hay que tratar de\n",
    "evitar mezclar los verdaderos positivos y negativos..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6iVwHYZwEw6R"
   },
   "source": [
    "### Precisión, cobertura y F1 Score\n",
    "\n",
    "Para sortear los problemas anteriores es frecuente utilizar las siguiente dos métricas\n",
    "\n",
    "**Precisión**: cantidad de casos correctamente rotulados como positivos sobre el total de predicciones positivas, $TP / (TP + FP)$.\n",
    "\n",
    "**Cobertura o Recall**: proporción de instancias positivas que el algoritmo logra identificar sobre el total de casos positivos ($TP / (TP + FN)$)\n",
    "\n",
    "Depende del contexto puede ser deseable maximizar una o la otra\n",
    "\n",
    "Si es una enfermerdad rara, por caso, nos interesa más la cobertura que la precisión. \n",
    "\n",
    "**¿Para un filtro de spam?**\n",
    "\n",
    "\n",
    "En determinadas situaciones ambos métricas son importantes y tiene sentido combinarlas:\n",
    "\n",
    "$$F_{1} = 2\\frac{p\\cdot r}{p + r}$$\n",
    "\n",
    "Pesa por igual a ambas métricas (media harmónica) y el valor suele estar cerca del mínimo de las métrica.\n",
    "\n",
    "Esta acotado al intervalo $[0, 1]$ y vale 1 únicamente para un clasificador perfecto.\n",
    "\n",
    "Valores superiores a 0.7 son propios de un \"buen\" clasificador.\n",
    "\n",
    "Desventaja: no hace un juicio sobre como el modelo clasifica las instancias negativas\n",
    "\n",
    "![](https://miro.medium.com/max/1336/1*uzJKEMrjHEv9DBAGNke3EQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6qSOafyzFyqP"
   },
   "source": [
    "### La curva ROC\n",
    "\n",
    "![](https://raw.githubusercontent.com/petobens/introduccion-ml-aplicado/class3/figures/ml-claro-1/roc.png)\n",
    "\n",
    "Características:\n",
    "\n",
    "Para definir pertenencia a una clase hay un umbral, $p$, tal que si $p=0$ (1) siempre (nunca) predigo que las observaciones son positivas entonces ambos TPR (TP / P) y FPR (FP/ N) valen 1 (0).\n",
    "\n",
    "Curva 45 grados define a un clasificador aleatorio y la coordenada $(0,1)$ a un clasificador perfecto.\n",
    "\n",
    "Intuitivamente si elegimos aleatoriamente una observacion positiva y una negativa el area bajo la curva es la probabilidad de que el clasificador rankee más alto al positivo.\n",
    "\n",
    "**Conviene utilizar una única métrica para guiar las decisiones**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8n54oZ5XGoJg"
   },
   "source": [
    "## Fitteo del modelo\n",
    "\n",
    "Ejercicios: Fit Regresión Logística\n",
    "1. Alguno algoritmos, en Python, soportan exclusivamente atributos numéricos. Escriba en consecuencia una función para convertir todos los atributos categóricos. \n",
    "2. Fitee una regresión logística sobre la data de entrenamiento y genere predicciones (y probabilidades) para la data de test/validación.\n",
    "3. Evalue estas predicciones usando métricas de accuracy y ROC para el conjunto de entrenamiento y ROC para el conjunto de validación.\n",
    "4. Bonus: investigue que es la metrica F1 y utilice scikit-learn o escriba una función que compute dicha métrica y\n",
    "con ello evalué nuevamente los resultados para ambos conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PUOQNaLzF_fA"
   },
   "outputs": [],
   "source": [
    "df['home.dest'].value_counts().index.values[0: 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-xAqx2iF_fC"
   },
   "outputs": [],
   "source": [
    "def _encode_categorical(df, top=20):\n",
    "    logger.info(\"Filtering categorical columns top values...\")\n",
    "    cat_cols = _get_typed_cols(df, col_type='cat')\n",
    "    logger.info(f\"Categorical columns:\\n {cat_cols}\")\n",
    "\n",
    "    for c in cat_cols:\n",
    "        top_categories = df[c].value_counts().index.values[0:top]\n",
    "        logger.info(f\"Top categories for {c}:\\n {top_categories}\")\n",
    "        df[c] = df[c].where(df[c].isin(top_categories), other='OTHER')\n",
    "\n",
    "    logger.info(\"Getting dummies from top categories...\")\n",
    "    df = pd.get_dummies(df, columns=cat_cols, drop_first=False)\n",
    "    logger.info(\n",
    "        f\"{len(df.columns)} columns after dummies:\\n \" f\"{sorted(df.columns.tolist())}\"\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gfvMVvgcF_fE"
   },
   "outputs": [],
   "source": [
    "df = _encode_categorical(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8SWeRrcfF_fF"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QJEZMwmMF_fI"
   },
   "outputs": [],
   "source": [
    "df_train = df[df['train']]\n",
    "df_test = df[~df['train']]\n",
    "y_train = df_train['survived']\n",
    "y_test = df_test['survived']\n",
    "X_train = df_train.drop(['survived', 'train'], axis=1)\n",
    "X_test = df_test.drop(['survived', 'train'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ha-Ke15lF_fM"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9jbcsb8pF_fN"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "y_pred_proba = lr.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O5sLFSu2F_fP"
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6jOy8nA5F_fR"
   },
   "outputs": [],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LT7wXBVpF_fT"
   },
   "outputs": [],
   "source": [
    "lr.score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FJRZoQwFF_fU"
   },
   "outputs": [],
   "source": [
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YMVSY0IvF_fZ"
   },
   "outputs": [],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3eGkvkVIF_fb"
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J9OEMnNqF_fd"
   },
   "outputs": [],
   "source": [
    "roc_score = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EyWa_S4dF_fg"
   },
   "outputs": [],
   "source": [
    "cr = metrics.classification_report(y_test, y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N31s4ibYF_fk"
   },
   "source": [
    "## Árboles de decisión y aleatorios\n",
    "\n",
    "Ejercicios\n",
    "\n",
    "1. Fittee un árbol de decisión en vez de una regresión logística y compare la\n",
    "performance de los modelos.\n",
    "  * Bonus: Grafique el árbol de decision resultante\n",
    "2. Repita el punto anterior pero ahora con un bosque aleatorio.\n",
    "  * Bonus: Pruebe aumentar la profundidad del árbol. ¿Mejora su métrica de\n",
    "performance?\n",
    "3. Compute y grafique la importancia de atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HK6bkXS1F_fk"
   },
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2eH4ghNeF_fl"
   },
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "y_pred_proba = dt.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MD7cKpzEF_fn"
   },
   "outputs": [],
   "source": [
    "tree.plot_tree(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5KadJsRyF_fp"
   },
   "outputs": [],
   "source": [
    "dt.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ngJCivaZF_fr"
   },
   "outputs": [],
   "source": [
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wSScOikLF_ft"
   },
   "outputs": [],
   "source": [
    "# Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dl2gJ93OF_fv"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=7, n_jobs=-1, verbose=2,)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred_proba = rf.predict_proba(X_test)[:, 1]\n",
    "print(rf.score(X_train, y_train))\n",
    "print(rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uhx-6_CmF_fx"
   },
   "outputs": [],
   "source": [
    "roc_score = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vMfQrXyBF_fz"
   },
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "feat_import = list(\n",
    "zip(np.asanyarray(X_train.columns)[indices], importances[indices])\n",
    ")\n",
    "feat_import = pd.DataFrame(feat_import, columns=['feature', 'importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vaKKm2ydF_f0"
   },
   "outputs": [],
   "source": [
    "feat_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FV50qF2VF_f3"
   },
   "outputs": [],
   "source": [
    "ax = feat_import[:20].plot(kind='bar')\n",
    "ax.set_xticklabels(feat_import[:20]['feature'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L6a7rPoJF_f7"
   },
   "source": [
    "## Ejercicios Finales\n",
    "\n",
    "1. Aplicando lo aprendido en este notebook desarrolle uno nuevo con lo que considere más relevante y utilizando el RandomForestClassifier y submitee sus predicciones a la competencia de datos del Titanic https://www.kaggle.com/c/titanic/overview\n",
    "\n",
    "2. Revise en detalle alguno de los dos noteobooks e incopore mejoras a su notebook para mejorar la predicción:\n",
    "\n",
    "  https://www.kaggle.com/masumrumi/a-statistical-analysis-ml-workflow-of-titanic\n",
    "\n",
    "  https://www.kaggle.com/rp1611/step-by-step-tutorial-for-beginners\n",
    "\n",
    "3. Pruebe los resultados utilziando algún estimador de Boosting como LightGBM. Qué diferencias observa?\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "6S-eima3F_eU"
   ],
   "name": "starter_clasificacion_titanic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
