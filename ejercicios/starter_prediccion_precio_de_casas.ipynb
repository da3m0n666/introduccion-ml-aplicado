{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YgXzXxbG41mD"
   },
   "source": [
    "# Predicción de Precio de Casas\n",
    "\n",
    "![](https://storage.googleapis.com/kaggle-datasets-images/128/270/d149695d1f9a97ec54cf673be6430ad7/dataset-original.jpg)\n",
    "\n",
    "*Objetivo: predecir precio de casas en King County en el estado de Washington (data de [Kaggle](https://www.kaggle.com/harlfoxem/housesalesprediction)).*\n",
    "\n",
    "\n",
    "Pensemos primero en un modelo lineal simple utilizando solamente los metros cuadrados:\n",
    "$$ \\log(price) = \\beta_{0} + \\beta_{1}m2 + \\varepsilon $$\n",
    "\n",
    "Interpretabilidad: la ordenada al origen es el precio inicial de una casa y la pendiente cuanto crece este por metro cuadrado.\n",
    "\n",
    "En la misma línea: **¿por qué en logaritmos?** -> *Power Law/Fat Tails*\n",
    "\n",
    "Para medir la bondad de ajuste usamos el error cuadrático medio (ECM):\n",
    "$$ ECM = \\frac{1}{N} \\sum_{i=1}^{N}(y_{i} - \\hat{f}(x_{i}))^{2} =\n",
    "          \\sum_{i=1}^{N}(\\log(price_{i}) - \\beta_{0} + \\beta_{1}m2_{i})^{2} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0DryBXoF41mF"
   },
   "source": [
    "## Modelo Lineal Univariado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "15_g8DzQ41mG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gH7JRN9441mN"
   },
   "source": [
    "### SIN DATOS NO HAY PARAISO\n",
    "![](https://raw.githubusercontent.com/petobens/introduccion-ml-aplicado/master/figures/ml-claro-1/whatido.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AzBN-6rUKKti"
   },
   "source": [
    "#### Obteniendo el dataset de Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "uvy01K2AKI1B",
    "outputId": "fe02f884-0276-4fe6-d27d-8ce7717ab772"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FNIpIs9vKSSx",
    "outputId": "5846fdc6-4a02-437f-d6dc-6121873ff208"
   },
   "outputs": [],
   "source": [
    "!pip install -q kaggle\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!ls ~/.kaggle\n",
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "QORrLWKXKa2x",
    "outputId": "ba538c26-0e03-4689-9585-450c7dcf8051"
   },
   "outputs": [],
   "source": [
    "!kaggle datasets download -d harlfoxem/housesalesprediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JzWOk_kLKNyq"
   },
   "source": [
    "#### Cargar el dataset con Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QmJBg24S41mP"
   },
   "outputs": [],
   "source": [
    "def extract_housing_prices_data():\n",
    "    #url_csv = 'https://storage.googleapis.com/qeds/data/kc_house_data.csv'\n",
    "    df = pd.read_csv('housesalesprediction.zip')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5DF8ccMd41mV"
   },
   "outputs": [],
   "source": [
    "df = extract_housing_prices_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "JSYuKYA341mb",
    "outputId": "7a707fd3-77d3-4cb0-ca55-0e5b83fb5981"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "colab_type": "code",
    "id": "Qsetb9SM41mj",
    "outputId": "c15eba08-6822-46cf-a890-c85bb664cb38"
   },
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "hGqgscYp41mp",
    "outputId": "ceb5dbef-b998-4c2b-ebd6-12213c549212"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BiFETJ9J41mx"
   },
   "source": [
    "## Un poco de EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yvb3yFqS41mz"
   },
   "source": [
    "### EDA y ETFL\n",
    "\n",
    "EDA: Exploratory Data Analysis/Análisis Estadístico Descriptivo\n",
    "\n",
    "**Data Mining**: en su acepción pura son técnicas para analizar los datos, encontrar patrones y generar insights.\n",
    "\n",
    "- **Visualizaciones:** univariadas (para un mismo feature), bi-variadas (entre features y target), multivariadas (entre distintos features)\n",
    "- **Técnicas de estadística clásica:** correlaciones, test de hipótesis, ANOVA.\n",
    "- **Reducción de dimensionalidad:** PCA, SVD\n",
    "- **Clustering**\n",
    "\n",
    "**Objetivos:**\n",
    "- Comprender el dataset.\n",
    "- Definir y refinar la selección e ingeniería de atributos que alimentan los modelos.\n",
    "\n",
    "\n",
    "¿Qué involucra hacer data science en la industria?\n",
    "**E**xtract **T**ransform **F**it **L**oad\n",
    "\n",
    "Distribución de tiempos: **E 30\\% | T 50\\% | F 10\\% | L 10\\%**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "colab_type": "code",
    "id": "RX2T4HiY41m0",
    "outputId": "ef23cd72-0bfe-4fb7-d981-58a8cbea4511"
   },
   "outputs": [],
   "source": [
    "df['bedrooms'].value_counts().to_frame().reset_index().sort_values(by='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "jpmk-4op41m8",
    "outputId": "1e53ce8a-c18a-4a6e-d701-c180bee9d2ec"
   },
   "outputs": [],
   "source": [
    "df['price'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "colab_type": "code",
    "id": "6Ws_XjRB41nE",
    "outputId": "cf6b04e1-ef6d-469f-e6d9-c211f3e7e0af"
   },
   "outputs": [],
   "source": [
    "df1 = df[['bedrooms', 'bathrooms', 'price']]\n",
    "df1.hist(bins=25,xlabelsize='10',ylabelsize='10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "colab_type": "code",
    "id": "EuTbpW8K41nO",
    "outputId": "3fd7ebe1-8ac8-43f3-c2b3-7fc8432987d8"
   },
   "outputs": [],
   "source": [
    "df_corr = df.corr('pearson')\n",
    "df_corr.style.background_gradient(cmap='coolwarm', axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PxM2MrYa41nV"
   },
   "outputs": [],
   "source": [
    "def scatter_wrapper(df, ax=None, x='sqft_living', y='price', color='b'):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(figsize=(8, 6))\n",
    "    df.plot.scatter(x=x , y=y, c=color, alpha=0.35, s=1.5, ax=ax)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "colab_type": "code",
    "id": "Hs72J84m41nd",
    "outputId": "c1899918-1821-4f6b-ae53-7954ad1cf329"
   },
   "outputs": [],
   "source": [
    "scatter_wrapper(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H2hiNFXy41nj"
   },
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FZchhZ2q41nk"
   },
   "source": [
    "### Transformacion: Ingenieria\n",
    "\n",
    "![](https://www.oreilly.com/library/view/feature-engineering-for/9781491953235/assets/feml_0102.png)\n",
    "\n",
    "El \"aprendizaje\" del modelo dependerá de la información y variabilidad provista por los atributos (*Garbage in - garbage out*).\n",
    "\n",
    "Existe gran variedad de técnicas para generar/modificar atributos\n",
    "\n",
    "- **Transformaciones logaritmicas:** tiene sentido cuando variables siguen una distribución asimétrica positiva (masa concentrada en valores pequeños y grandes con poca densidad)\n",
    "- **Reescalamiento de variables numéricas:** si el modelo es sensible a la escala del atributo es deseable hacer transformaciones tipo *estandarización*.\n",
    "(Esto puede ser propenso a *data leakage*)\n",
    "- **Binning:** agrupación en *bins* ordenados\n",
    "- **One-hot encoding:** transformación de variables categóricas en variables contínuas. ![](https://raw.githubusercontent.com/petobens/introduccion-ml-aplicado/master/figures/ml-claro-1/one_hot.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "bnoA6uHy41nl",
    "outputId": "ddcba3cc-00b9-46c7-e28e-9bceb22169c5"
   },
   "outputs": [],
   "source": [
    "df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "Y-P3cGkP41nr",
    "outputId": "da74b857-a803-4c2c-ccf4-9effccbc95d5"
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(df['date']).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ougG_dKB41nx"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    df['sales_yr'] = pd.to_datetime(df['date']).dt.year\n",
    "    df['log_price'] = np.log(df['price'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "19dkB6C241n4"
   },
   "outputs": [],
   "source": [
    "df = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "VfTHQWAX41n_",
    "outputId": "540b9ef4-468d-42ea-d35d-dfb5e2160874"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "id": "Sgi_nH9N41oE",
    "outputId": "9850ebc0-f390-470d-e66a-6c13e328c10b"
   },
   "outputs": [],
   "source": [
    "scatter_wrapper(df, y='log_price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tg4DOM7441oK"
   },
   "outputs": [],
   "source": [
    "def xy_split(df):\n",
    "    y = df['log_price']\n",
    "    X = df.drop(['price', 'log_price', 'date', 'id'], axis=1).copy()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6QuZ-jNV41oO"
   },
   "outputs": [],
   "source": [
    "X, y = xy_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "AlDpfvd641oS",
    "outputId": "6e89f545-e889-421e-a840-5550e438b3f4"
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "SyHvqNPN41oX",
    "outputId": "abbdc426-5691-4fbd-c583-e2fb7b7ffc96"
   },
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lf-TUtmR41ob"
   },
   "outputs": [],
   "source": [
    "def fit(X, y, x_cols=None):\n",
    "    lr_model = linear_model.LinearRegression()\n",
    "    X = X if x_cols is None else X[x_cols]\n",
    "    lr_model.fit(X, y)\n",
    "    return lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bSsjkNCy41of"
   },
   "outputs": [],
   "source": [
    "lr_model = fit(X, y, x_cols=['sqft_living'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z9R_ZC1T41ok"
   },
   "outputs": [],
   "source": [
    "beta_0, beta_1 = lr_model.intercept_, lr_model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XbAJa3t441oo",
    "outputId": "6acd0838-520d-4e66-bff5-520b410f7e37"
   },
   "outputs": [],
   "source": [
    "beta_0, beta_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "id": "Q3D_YM3A41os",
    "outputId": "ac43cbd3-8a4f-4641-918f-1535fd560426"
   },
   "outputs": [],
   "source": [
    "# Plotear predicción\n",
    "ax = scatter_wrapper(df, y='log_price')\n",
    "x = np.array([0, df['sqft_living'].max()])\n",
    "ax.plot(x, beta_0 + beta_1*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gwLLvvAg41ov"
   },
   "outputs": [],
   "source": [
    "def predict(model, X, exp=False):\n",
    "    y_pred = model.predict(X)\n",
    "    if exp:\n",
    "        y_pred = np.exp(y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DtGbEzei41oz",
    "outputId": "6334d270-80ea-4a84-da91-1a9688a8ee8c"
   },
   "outputs": [],
   "source": [
    "predict(lr_model, [[5000]], exp=True) # Nota: esto es un array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DtA7u1Jh41o3"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dTC509-241o6"
   },
   "outputs": [],
   "source": [
    "def score(y, y_hat):\n",
    "    mse = mean_squared_error(y, y_hat)\n",
    "    print(f\"MSE is {mse}\")\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "txnbujer41o9"
   },
   "outputs": [],
   "source": [
    "y_hat = predict(lr_model, X[['sqft_living']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "_PATAXAd41pB",
    "outputId": "7651c6b5-2036-4ed4-c61b-8fe3213d50d5"
   },
   "outputs": [],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "MuuTkQ3a41pE",
    "outputId": "d5d924dc-9394-4759-ea80-b009b7c72d25"
   },
   "outputs": [],
   "source": [
    "score(y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "htrc4xtc41pG"
   },
   "source": [
    "## Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JmOJ8w-U41pH"
   },
   "source": [
    "### Ejercicios Regresion Lineal Simple\n",
    "\n",
    "1. **Caching**\n",
    "Modifique la función que extrae los datos de forma tal que guarde una copia local de los  mismos en caso que esta no exista aun. Si este archivo existe entonces devolver los datos ya guardados a menos que expresamente se quiere rehacer la consulta.\n",
    "2. **Sistema métrico**\n",
    "  1. Escriba una función que convierta metros cuadrados a pies cuadrados.\n",
    "  2. Use la función anterior para estimar el precio de un vivienda con 464 m2 de living.\n",
    "3. **Regresión lineal multivariada**\n",
    "  1. Ajuste ahora un modelo con la totalidad de los features: $Y = X\\beta + \\varepsilon$\n",
    "  2. En un mismo plano (`sqft_living`, `log_price`), grafique una nube de puntos con la data actual, los valores predicho por el modelo simple y aquellos predichos por este modelo multivariado.\n",
    "  3. Compare el error cuadrático medio de los dos modelos.\n",
    "  4. *Feature Engineering:* cree una nueva variable que refleje la fracción de pies no subterraneos y reestime el modelo con este nuevo atributo. ¿Encuentra mejoras en performance?\n",
    "4. In Sample versus Out Of Sample\n",
    "  1. Para pensar: ¿con lo hecho hasta ahora puede usted asegurar que su modelo performará correctamente con datos desconocidos?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y3_5A0x941pI"
   },
   "source": [
    "### Ejercicio 1: Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udn0Ru3R41pI"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def extract_housing_prices_data_with_cache(cache_fn='hp_data.csv', refresh_cache=False):\n",
    "    ## TODO: implementar\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZbSJBzY341pL"
   },
   "outputs": [],
   "source": [
    "df_cache = extract_housing_prices_data_with_cache(refresh_cache=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jXNPDx5941pO"
   },
   "source": [
    "### Ejercicio 2: Sistema metrico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y1657M2I41pO"
   },
   "outputs": [],
   "source": [
    "##TODO: implementar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhWDM5e341pT"
   },
   "outputs": [],
   "source": [
    "predict(lr_model, [[m2_to_sqft(464)]], exp=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oHX19BlN41pW"
   },
   "source": [
    "### Ejercicio 3: Regresión multivariada y feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QIQWRB2k41pX"
   },
   "outputs": [],
   "source": [
    "lr_model_full = fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LGD_SelO41pa"
   },
   "outputs": [],
   "source": [
    "x = 'sqft_living'\n",
    "size = 1.5\n",
    "ax = scatter_wrapper(df, y='log_price')\n",
    "ax.scatter(X[x], predict(lr_model_full, X), c='r', s=size)\n",
    "ax.scatter(X[x], predict(lr_model, X[[x]]), c='y', s=size)\n",
    "ax.legend(['data', 'full', 'sqft'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A4ujDGTt41pe"
   },
   "outputs": [],
   "source": [
    "X_fe = X.copy()\n",
    "X_fe['pct_sqft_above'] = X_fe['sqft_above'] / X['sqft_living']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yCt4PnBP41pi"
   },
   "outputs": [],
   "source": [
    "X_fe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1DuwvIj_41pm"
   },
   "outputs": [],
   "source": [
    "lr_model_full_above = fit(X_fe, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4MyHOKpc41pq"
   },
   "outputs": [],
   "source": [
    "y_hat_full_above = predict(lr_model_full_above, X_fe)\n",
    "mse_full_above = score(y, y_hat_full_above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iBrH0yT341pt"
   },
   "outputs": [],
   "source": [
    "y_hat_full = predict(lr_model_full, X)\n",
    "mse_full = score(y, y_hat_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z3y9EEE841pv"
   },
   "source": [
    "## Seleccion de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YmntuH1O41pw"
   },
   "source": [
    "### Selección de modelos: Conjunto de Validación\n",
    "\n",
    "Hasta ahora hemos visto un único modelo y calculado una métrica de performance sobre el conjunto de entrenamiento\n",
    "Pero... **queremos predecir bien sobre datos desconocidos!**\n",
    "\n",
    "\n",
    "¿Cómo hacerlo? Simulamos la división entre datos conocidos y desconocidos.\n",
    "\n",
    "*Enfoque de validation/holdout set:* entrenamos el modelo con datos conocidos y validamos las predicciones con el *conjunto de validación* (desconocido)\n",
    "\n",
    "El conjunto de validación es una submuestra al azar de observaciones del conjunto de entrenamiento (usualmente 20%)\n",
    "\n",
    "Posible problemas: \n",
    "\n",
    "1. La predicción de performance tiene alta variabilidad ya que depende de la participación de observaciones en entrenamiento/validación. \n",
    "2. Al achicar el conjunto de entrenamiento podemos estar sobrestimando el error de test.\n",
    "\n",
    "![](https://raw.githubusercontent.com/petobens/introduccion-ml-aplicado/master/figures/ml-claro-1/holdout.png)\n",
    "\n",
    "**¿Definido el modelo final: qué observaciones usamos para entrenarlo?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fJHIJRCs41pw"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pOEI5ed741pz"
   },
   "outputs": [],
   "source": [
    "def fit(X, y, x_cols=None, model='lr', max_depth=None):\n",
    "    if model == 'lr':\n",
    "        clf = linear_model.LinearRegression()\n",
    "    elif model == 'dt':\n",
    "        clf = DecisionTreeRegressor(max_depth=max_depth)\n",
    "    elif model == 'rf':\n",
    "        clf = RandomForestRegressor()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model!\")\n",
    "\n",
    "    X = X if x_cols is None else X[x_cols]\n",
    "    clf.fit(X, y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DsEztPJg41p2"
   },
   "outputs": [],
   "source": [
    "dt_model = fit(X, y, model='dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O7VzG0R241p4"
   },
   "outputs": [],
   "source": [
    "dt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OU3qnIPN41p9"
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "test_n = 50\n",
    "X_train = X.iloc[:test_n, :]\n",
    "y_train = y.iloc[:test_n]\n",
    "X_test = X.iloc[test_n:, :]\n",
    "y_test = y.iloc[test_n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Zyox7SI41qA"
   },
   "outputs": [],
   "source": [
    "X.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RTgsjTpv41qI"
   },
   "outputs": [],
   "source": [
    "def fit_pipeline(X_train, y_train, X_test, y_test, model, max_depth=None):\n",
    "    m = fit(X_train, y_train, model=model, max_depth=max_depth)\n",
    "    mses = {}\n",
    "    for phase in ['train', 'test']:\n",
    "        X = X_train if phase == 'train' else X_test\n",
    "        y = y_train if phase == 'train' else y_test\n",
    "        y_hat = predict(m, X)\n",
    "        print(f\"{phase} phase:\")\n",
    "        mses[phase] = score(y, y_hat)\n",
    "    return mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WZH1awPI41qL"
   },
   "outputs": [],
   "source": [
    "fit_pipeline(X_train, y_train, X_test, y_test, 'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3KhruyeH41qQ"
   },
   "outputs": [],
   "source": [
    "fit_pipeline(X_train, y_train, X_test, y_test, 'dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ITFaJ31b41qS"
   },
   "outputs": [],
   "source": [
    "# Hagamos tuning del hiperparámetro de profundidad de los árboles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qCh7YcAT41qU"
   },
   "outputs": [],
   "source": [
    "depths = range(1, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9XsgpYdB41qY"
   },
   "outputs": [],
   "source": [
    "max_depths = range(1, 15)\n",
    "df_mse = pd.DataFrame()\n",
    "for max_depth in max_depths:\n",
    "    mse = fit_pipeline(X_train, y_train, X_test, y_test, 'dt', max_depth=max_depth)\n",
    "    mse['max_depth'] = max_depth\n",
    "    df_mse = df_mse.append(mse, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZC9ITfum41qb"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "df_mse.plot(x='max_depth', y='test', c='r', ax=ax)\n",
    "df_mse.plot(x='max_depth', y='train', c='b', ax=ax)\n",
    "ax.set_xlabel('max_depth')\n",
    "ax.set_ylabel('ECM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cofKPdj2b4ph"
   },
   "source": [
    "### Validación Cruzada\n",
    "\n",
    "![]()![image.png](https://raw.githubusercontent.com/petobens/introduccion-ml-aplicado/master/figures/ml-claro-1/cv_k_fold.png)\n",
    "\n",
    "¿Cómo podemos resolver los problemas de la estrategia de holdout?\n",
    "\n",
    "Una opción es hacer **k-fold cross validation:**\n",
    "\n",
    "1. Particionar el dataset en $k$ subconjuntos (folds) de tamaño parecido.\n",
    "2. Usar el enésimo fold como conjunto de validación y el resto como conjunto de entrenamiento computando el ECM en cada caso.\n",
    "3. Aproximar el error de *test* promediando sobre los ECM: $CV_{(k)} = \\frac{1}{k}\\sum_{i=1}^{k}EMC_{i}$\n",
    "\n",
    "Algunas observaciones relevantes:\n",
    "\n",
    "1. Si hacemos $k = N$ entonces el método se llama *Leave-One-Out Cross-Validation* (LOOCV) (pero esto es costoso computancionalmente)\n",
    "2. En general se usan valores de $k=5$ o $k = 10$. ¿Por qué?\n",
    "3. Todos estos métodos asumen que las observaciones son i.i.d...\n",
    "\n",
    "\n",
    "### Overfitting, modelos e hiperparametros\n",
    "\n",
    "Con las estrategias de holdout tenemos una forma de aproximar el error de testeo y detectar casos de overfitting: ¿cómo reducimos este problema?\n",
    "\n",
    "Podemos probar distintos modelos (*no free-lunch theorem*)\n",
    "\n",
    "Podemos optimizar aquellos parámetros de un mismo modelo que no se derivan del proceso de aprendizaje: los *hiperparámetros*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n7WVt0nZ41qf"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=0)\n",
    "df_mse_cv = pd.DataFrame()\n",
    "for max_depth in max_depths:\n",
    "    df_row = {'max_depth': max_depth}\n",
    "    max_depth_mses = []\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        m = DecisionTreeRegressor(max_depth=max_depth)\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf = m.fit(X_train, y_train)\n",
    "        y_hat = clf.predict(X_test)\n",
    "        mse = score(y_test, y_hat)\n",
    "        max_depth_mses.append(mse)\n",
    "    df_row['max_depth_mse_cv'] = np.mean(max_depth_mses)\n",
    "    df_mse_cv = df_mse_cv.append(df_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kFnnUXGu41qh"
   },
   "outputs": [],
   "source": [
    "df_mse_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vZeQFtIE41ql"
   },
   "outputs": [],
   "source": [
    "df_mse_cv[df_mse_cv['max_depth_mse_cv'] == df_mse_cv['max_depth_mse_cv'].min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hwjoFZwN41qn"
   },
   "source": [
    "### Ejercicios Selección de Modelos\n",
    "\n",
    "1. **Overfitting y validation set**\n",
    "  1. Escriba una función que separe el conjunto de datos en entrenamiento y validación a partir de un parámetro que determina el tamaño del segundo conjunto.\n",
    "  2. Utilice ahora la función `model_selection.train_test_split` para realizar la separación del inciso anterior.\n",
    "  3. Empleando alguna de las dos funciones de los incisos anteriores investigue la existencia de overfitting para distintos tamaños del conjunto de validación.\n",
    "2. **Más feature engineering: binning y dummies**\n",
    "  1. Cree una nueva variable `age` que refleje la antigüedad de las casas al ser vendidas.\n",
    "  2. Genere nuevos features a partir de esta columna usando una estrategia de `binning` (y `dummies`).\n",
    "  3. Fittee un nuevo modelo Lasso con estos features ampliados y compute el ECM. Comparelo con el modelo completo sin feature engineering.\n",
    "    1. ¿Estas transformaciones las debe hacer también en el conjunto de validacion?\n",
    "3. **Validación cruzada e hiperparametros**\n",
    "  1. Utilizando ahora la función `cross_val_score` del módulo `sklearn.model_section` repita el ejercicio de validación cruzada y obtenga los ECM para cada valor del hiperparámetros $alpha$ (en logaritmos).\n",
    "  2. Grafique los errores cuadráticos medios resultantes.\n",
    "  3. A partir del modelo `LassoCV` obtenga nuevamente el hiperparámetro óptimo.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "76fRr29N41qn"
   },
   "source": [
    "### Ejercicio 1: Overfitting  y validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ipgWcKvH41qo"
   },
   "outputs": [],
   "source": [
    "np.random.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0yjQPaDH41qq"
   },
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(X)) <= 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fmTJooD441qs"
   },
   "outputs": [],
   "source": [
    "msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s6kkF1y341qu"
   },
   "outputs": [],
   "source": [
    "msk.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jmfVpsYO41qw"
   },
   "outputs": [],
   "source": [
    "X[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wxr1Qdhb41qy"
   },
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size=0.2):\n",
    "    bool_mask = np.random.rand(len(X)) <= (1 - test_size)\n",
    "    X_train, X_test = X[bool_mask], X[~bool_mask]\n",
    "    y_train, y_test = y[bool_mask], y[~bool_mask]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06Ff28x941q3"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6sTiGyWy41q5"
   },
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHSJzZJK41q8"
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VHUfvsOa41q_"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r_AYapVI41rC"
   },
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-sUFr8AB41rF"
   },
   "outputs": [],
   "source": [
    "for i in np.arange(0.1, 0.6, 0.1):\n",
    "    print(f\"Test size {i}\")\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=i)\n",
    "    print(f\"Model lineal\")\n",
    "    fit_pipeline(X_train, y_train, X_test, y_test, 'lr')\n",
    "    print(f\"Model Decision Tree\")\n",
    "    fit_pipeline(X_train, y_train, X_test, y_test, 'dt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RYGHdMGw41rH"
   },
   "source": [
    "### Ejercicio 2: binning y dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y2JDowSt41rI"
   },
   "outputs": [],
   "source": [
    "X_bd = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vc326OnL41rL"
   },
   "outputs": [],
   "source": [
    "X_bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pUzGZSMt41rO"
   },
   "outputs": [],
   "source": [
    "# TODO: implementar X_bd['age'] = \n",
    "X_bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W5VZxiSj41rR"
   },
   "outputs": [],
   "source": [
    "X_bd['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5KU1Gcxd41rT"
   },
   "outputs": [],
   "source": [
    "bins = [-2, 0, 5, 10, 25, 50, 75, 100, 100000]\n",
    "labels = ['<1', '1-5', '6-10', '11-25', '26-50', '51-75', '76-100', '>100']\n",
    "#TODO: implementar X_bd['age_binned'] = \n",
    "X_bd[['age', 'age_binned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2zgBldlt41rW"
   },
   "outputs": [],
   "source": [
    "# TODO implementar dummies X_bd = \n",
    "X_bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CYC9Qz6v41ra"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_bd, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-vdUXlAr41rc"
   },
   "outputs": [],
   "source": [
    "fit_pipeline(X_train, y_train, X_test, y_test, 'dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xi1rrX_M41re"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HhTla3kO41rg"
   },
   "outputs": [],
   "source": [
    "fit_pipeline(X_train, y_train, X_test, y_test, 'dt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-w4XtelV41ri"
   },
   "source": [
    "### Ejercicio 3: Validacion cruzada e hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DcpkoymU41ri"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4rFElmtI41rk"
   },
   "outputs": [],
   "source": [
    "df_mse_sk = pd.DataFrame()\n",
    "for max_depth in max_depths:\n",
    "    df_mse_sk_row = {'max_depth': max_depth}\n",
    "    cv_score = -cross_val_score(DecisionTreeRegressor(max_depth=max_depth, random_state=0), X, y, cv=5, \n",
    "                               scoring='neg_mean_squared_error')\n",
    "    df_mse_sk_row['cv'] = np.mean(cv_score)\n",
    "    df_mse_sk = df_mse_sk.append(df_mse_sk_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K0jgbjrG41rl"
   },
   "outputs": [],
   "source": [
    "df_mse_sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YF-YBFB-41rn"
   },
   "outputs": [],
   "source": [
    "df_mse_sk[df_mse_sk['cv'] == df_mse_sk['cv'].min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EcurenDu41rq"
   },
   "source": [
    "## Modelos de Ensamble y Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yJfuAFbY41rq"
   },
   "source": [
    "### Sobre train, validation, test split\n",
    "\n",
    "¿Podemos overfittear el conjunto de validación?\n",
    "\n",
    "Si realizamos muchas pruebas posiblemente si\n",
    "\n",
    "Por eso en la práctica trabajamos con 3 conjuntos: entrenamiento, validación y testeo.\n",
    "\n",
    "![](https://raw.githubusercontent.com/petobens/introduccion-ml-aplicado/master/figures/ml-claro-1/tvt.png)\n",
    "\n",
    "En general se reserva 20% para testing y el remanente se divide en 80% entrenamiento y 20% validación.\n",
    "\n",
    "Con muchos datos los porcentajes son menores. Es una cuestión de representatividad y no de números.\n",
    "\n",
    "![](https://raw.githubusercontent.com/petobens/introduccion-ml-aplicado/master/figures/ml-claro-1/sample_size.png)\n",
    "\n",
    "\n",
    "### Tradeoff de Sesgo-Varianza\n",
    "\n",
    "¿Cuál es el valor esperado de ECM en una observación de testeo?\n",
    "\n",
    "Es decir cuál es el ECM promedio si uno estima sucesivas veces $f$ usando muchos conjuntos de entrenamiento y evaluando en cada $x_{0}$ del conjunto de test:\n",
    "\n",
    "$$E(y_{0} - \\hat{f}(x_{0}))^{2} = Var(\\hat{f}(x_{0})) +\n",
    "        \\left[Sesgo(\\hat{f}(x_{0}))\\right]^{2} + Var(\\varepsilon)$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "La varianza remite a cuánto cambiaría $\\hat{f}$ si estimaramos con otro conjunto de entrenamiento (idealmente queremos que sea poco).\n",
    "\n",
    "El sesgo alude a si $\\hat{f}$ está errando consistentemente en las predicciones ($Sesgo(\\hat{f}(x_{0})) = E[\\hat{f}(x_{0})] - y_{0}$).\n",
    "\n",
    "El ideal: tener un sesgo bajo y una varianza baja. ¿Es esto posible?\n",
    "\n",
    "![](https://prateekvjoshi.files.wordpress.com/2015/10/3-bulls-eye.png)\n",
    "\n",
    "![](https://miro.medium.com/max/492/1*blqnaVEu6Hbc-5ZYeDnU9Q.png)\n",
    "\n",
    "¿Por qué hay un tradeoff?\n",
    "\n",
    "- Es fácil obtener un método con bajo sesgo y alta varianza (dibujando una curva que pase por todos los puntos)\n",
    "- Es fácil obtener un método con bajo o nula varianza y alto sesgo (fitteando una constante)\n",
    "\n",
    "En general vale lo siguiente:\n",
    "\n",
    "- Métodos más complejos tienen alta varianza y bajo sesgo.\n",
    "- El fenómeno de *overfitting* se asocia a escenarios justamente de alta varianza y bajo sesgo.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MzFlrag7lDqp"
   },
   "source": [
    "### Bagging y Árboles aleatorios\n",
    "\n",
    "**Bagging**\n",
    "\n",
    "En general vale que agregar observaciones reduce la varianza.\n",
    "\n",
    "Podemos crear $B$ conjuntos de entrenamiento muestreando de forma aleatoria (y con reposición) del conjunto entrenamiento original (*bootstraping*).\n",
    "\n",
    "Si luego entrenamos sobre cada conjunto y promediamos reducimos la varianza (y tenemos bajo sesgo)\n",
    "$$\\hat{f}_{bag}(x) = \\frac{1}{B}\\sum_{b=1}^{B}\\hat{f}^{*b}(x)$$\n",
    "\n",
    "La predicción final es la clase más votada por los $B$ árboles (regla mayoritaria).\n",
    "\n",
    "**Random Forests**\n",
    "\n",
    "Ideado por Breiman con el objeto de mejorar aun más la performance predictiva.\n",
    "\n",
    "Al igual que en bagging se crean $B$ conjuntos de entrenamiento muestreando de forma aleatoria (y con reposición) del conjunto entrenamiento original.\n",
    "\n",
    "Para cada conjunto se hacer particionamiento recursivo pero al elegir los cortes se emplea un subconjunto aleatorio de la totalidad de atributos (*descorrelacionar*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IpS8JAiN41rq"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VY7NmYhC41rs"
   },
   "outputs": [],
   "source": [
    "fit_pipeline(X_train, y_train, X_test, y_test, 'rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2fJFMZm841ru"
   },
   "source": [
    "\n",
    "# Ejercicio\n",
    "\n",
    "Utilizando lo aprendido en este notebook y el anterior. \n",
    "Desarolle un pipeline para predecir el precio de casas del *Ames Housing dataset*.\n",
    "\n",
    "El link a la competencia es el siguiente: \n",
    "https://www.kaggle.com/c/home-data-for-ml-course/data\n",
    "\n",
    "Para obetener el dataset de train desde el notebook puede utilizar los siguientes comandos para dejar el archivo `train.csv` en el directorio actual.\n",
    "\n",
    "```\n",
    "!kaggle datasets download -d dansbecker/home-data-for-ml-course\n",
    "!unzip home-data-for-ml-course.zip\n",
    "```\n",
    "\n",
    "Comience por explorar los datos y fitear un modelo simple y calcular la métrica de error definida para la competencia para tener un baseline.\n",
    "\n",
    "Luego, vaya realizando feature engineering progresivamente y verificando como varía su métrica de performance. \n",
    "\n",
    "Eventualmente, cuando esté satisfecho con la performance, bajer el archivo `test.csv` de la web de la competencia y verifique la capacidad de generalización de su modelo.\n",
    "\n",
    "Como paso final, puede submitear su respuesta a la competencia siguiendo el formato descripto en la misma https://www.kaggle.com/c/home-data-for-ml-course/overview/evaluation\n",
    "\n",
    "Para esto hay que generar un archivo CSV con el formato designado y subirlo manualmente a https://www.kaggle.com/c/home-data-for-ml-course/submit\n",
    "\n",
    "O también puede probar utilizando la commandline app de kaggle de la siguiente manera:\n",
    "\n",
    "\n",
    "```\n",
    "!kaggle competitions submit home-data-for-ml-course -f my_submission.csv -m \"First Submission @pferrari\"\n",
    "```\n",
    "\n",
    "\n",
    "Referencia útil:\n",
    "\n",
    "https://stackoverflow.com/questions/49394737/exporting-data-from-google-colab-to-local-machine/49397357"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "JmOJ8w-U41pH",
    "y3_5A0x941pI",
    "jXNPDx5941pO",
    "oHX19BlN41pW",
    "hwjoFZwN41qn",
    "RYGHdMGw41rH",
    "-w4XtelV41ri",
    "2fJFMZm841ru"
   ],
   "name": "starter_prediccion_precio_de_casas.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
